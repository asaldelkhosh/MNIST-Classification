{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cbcf0c4b",
   "metadata": {},
   "source": [
    "# MNIST project\n",
    "\n",
    "Training a Neural Network Model for recognizing the numbers.\n",
    "\n",
    "Author: AsalDelkhosh\n",
    "Year: 2022\n",
    "\n",
    "This is a project about using non-negative matrix factorization for weight initialization in autoencoders.\n",
    "\n",
    "Autoencoders are a specific form of neural networks build by two parts. First part is used to encode the input data to a space with lower dimension and the second part decodes the abstracted data to reconstruct the input.\n",
    "\n",
    "The networks is trained in a way that the reocnstructed data is very similar to the original input. This way we can make sure that we are transferring enough information to a small encoded space so that we are enable to reconstruct the entire image from it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e46e4a6",
   "metadata": {},
   "source": [
    "## 1.import\n",
    "\n",
    "First we need to import some modules and libraries like numpy, tensorflow, keras and matplotlib.\n",
    "This libraries will help us to build our model and train it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8db3064",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38293591",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# displaying HTML\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0b222c6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# tensorflow\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m keras\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Input, Dense\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "# tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.datasets import mnist, fashion_mnist\n",
    "from tensorflow.keras.callbacks import TensorBoard, History\n",
    "# sklearn\n",
    "from sklearn.decomposition import NMF\n",
    "# numpy\n",
    "import numpy as np\n",
    "# matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# coounter\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084d811a",
   "metadata": {},
   "source": [
    "## 2.load data \n",
    "\n",
    "In the next part, we are going to load our databset into train data and train labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f634e05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cbd7cf8",
   "metadata": {},
   "source": [
    "### Data normalizing\n",
    "\n",
    "In this part we are going to normilize our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826cead6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "\n",
    "# reshaping our data\n",
    "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
    "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
    "\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c02e2474",
   "metadata": {},
   "source": [
    "### Selecting\n",
    "\n",
    "In this part we are going to select some of our samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01267075",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(x_test))\n",
    "\n",
    "selected_samples = np.zeros(10)\n",
    "l = []\n",
    "i = 0\n",
    "while len(l)<10:\n",
    "    if y_test[i] not in l:\n",
    "        l.append(y_test[i])\n",
    "        selected_samples[y_test[i]] = int(i)\n",
    "        i = i + 1\n",
    "    else:\n",
    "        i = i + 1\n",
    "selected_samples = list(selected_samples)\n",
    "selected_samples = [int(s) for s in selected_samples]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1431aeef",
   "metadata": {},
   "source": [
    "## Functions\n",
    "\n",
    "Our main functions for creating auto encoders and displaying the output images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27473a5d",
   "metadata": {},
   "source": [
    "### Displayin images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3262d161",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_images(x_test, decoded_imgs, selected_samples, image_type=[], name='reconstruction'):    \n",
    "    n = len(selected_samples)  # how many digits we will display\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    plt.title('Comparison of original and reconstructed image using different initialization methods')\n",
    "    image_type = ['Original Image']+image_type\n",
    "    for j in range(len(image_type)):\n",
    "        ax = plt.subplot(len(image_type), n+2, (j*(n+2)+1))\n",
    "        ax.text(0, 0.5, image_type[j], fontsize=16)\n",
    "        ax.axis(\"off\")\n",
    "        \n",
    "    for i in range(n):\n",
    "\n",
    "        # display original\n",
    "        ax = plt.subplot(len(image_type), n+2, i + 3)\n",
    "        plt.imshow(x_test[selected_samples[i]].reshape(28, 28))\n",
    "        plt.gray()\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "        for j in range(1,len(image_type)):\n",
    "            # display reconstruction with different initialization\n",
    "            ax = plt.subplot(len(image_type), n+2, i + 3 + (j)*(n+2))\n",
    "            plt.imshow(decoded_imgs[image_type[j]][selected_samples[i]].reshape(28, 28))\n",
    "            plt.gray()\n",
    "            ax.axis(\"off\")\n",
    "    plt.tight_layout()        \n",
    "    plt.subplots_adjust(hspace=0.05, wspace=0.05)\n",
    "    plt.savefig(name+'.png', dpi=200)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b1e381",
   "metadata": {},
   "source": [
    "### AutoEncoder\n",
    "\n",
    "Creating autoencoder based on our recognizing problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ad0bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_autoencoder(initializer=tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.05, seed=None)):\n",
    "    \n",
    "    if initializer!='nmf':\n",
    "        # inp\n",
    "        input_img = Input(shape=(784,))\n",
    "        encoded = Dense(128, activation='relu', kernel_initializer=initializer)(input_img)\n",
    "        encoded = Dense(64, activation='relu', kernel_initializer=initializer)(encoded)\n",
    "        encoded = Dense(32, activation='relu', kernel_initializer=initializer)(encoded)\n",
    "\n",
    "        decoded = Dense(64, activation='relu', kernel_initializer=initializer)(encoded)\n",
    "        decoded = Dense(128, activation='relu', kernel_initializer=initializer)(decoded)\n",
    "        decoded = Dense(784, activation='sigmoid', kernel_initializer=initializer)(decoded)\n",
    "        autoencoder = Model(input_img, decoded)\n",
    "        encoder = Model(input_img, encoded)\n",
    "        \n",
    "    else:\n",
    "        input_img = Input(shape=(784,))\n",
    "        encoded = Dense(128, activation='relu')(input_img)\n",
    "        encoded = Dense(64, activation='relu')(encoded)\n",
    "        encoded = Dense(32, activation='relu')(encoded)\n",
    "        \n",
    "        decoded = Dense(64, activation='relu')(encoded)\n",
    "        decoded = Dense(128, activation='relu')(decoded)\n",
    "        decoded = Dense(784, activation='sigmoid')(decoded)\n",
    "        \n",
    "        autoencoder = Model(input_img, decoded)\n",
    "        encoder = Model(input_img, encoded)\n",
    "    \n",
    "        init_weights = get_nmf_init_weights([784, 128, 64, 32])\n",
    "        autoencoder.set_weights(init_weights)\n",
    "    \n",
    "    autoencoder.compile(optimizer='adam', loss='mse')\n",
    "#     autoencoder.summary()\n",
    "    \n",
    "    return autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5368f60a",
   "metadata": {},
   "source": [
    "### Defining our methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9193d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = ['RandomNormal', 'GlorotNormal']\n",
    "small_sample_size = 3000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649bf2de",
   "metadata": {},
   "source": [
    "## Training our model\n",
    "\n",
    "In the next part we are going to build our model and train our model\n",
    "with the dataset that we loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec43ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper parameters\n",
    "sample_size='all'\n",
    "epochs = 50\n",
    "\n",
    "# auto encoders\n",
    "autoencoders = {}\n",
    "autoencoders['RandomNormal'] = build_autoencoder(initializer=tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.05, seed=None))\n",
    "autoencoders['GlorotNormal'] = build_autoencoder(initializer=tf.keras.initializers.GlorotNormal())\n",
    "\n",
    "\n",
    "# hist dictionary\n",
    "hist = {}\n",
    "for init_method in methods:\n",
    "    print(\"Training the model with \", init_method, \" initializer...\")\n",
    "    hist[init_method] = History()\n",
    "    # fitting our auto encoder\n",
    "    autoencoders[init_method].fit(x_train, x_train,\n",
    "                                  epochs=epochs,\n",
    "                                  batch_size=256,\n",
    "                                  shuffle=True,\n",
    "                                  validation_split=0.33,\n",
    "                                  callbacks=[hist[init_method]],\n",
    "                                  verbose=0)\n",
    "    \n",
    "# decoding images\n",
    "decoded_imgs = {}\n",
    "for init_method in methods:\n",
    "    decoded_imgs[init_method] = autoencoders[init_method].predict(x_test)\n",
    "    \n",
    "# displaying images\n",
    "display_images(x_test, decoded_imgs, selected_samples, image_type=methods, name='images/mnist_digit_reconstruction_'+str(sample_size)+'_'+str(epochs))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
